{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11679,
     "status": "ok",
     "timestamp": 1700113285037,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "1wauBJfp4CQM",
    "outputId": "2da2da30-f3d8-4760-92a1-48dcd9830712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabpfn\n",
      "  Downloading tabpfn-0.1.9-py3-none-any.whl (156 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m153.6/156.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.2.2)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.1.0+cu118)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\n",
      "Installing collected packages: tabpfn\n",
      "Successfully installed tabpfn-0.1.9\n",
      "Collecting captum\n",
      "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "Installing collected packages: captum\n",
      "Successfully installed captum-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabpfn\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5126,
     "status": "ok",
     "timestamp": 1700113290160,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "h_sDU12F4sEr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from captum.attr import DeepLift\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1700113290675,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "f2Vxr2VV41f_",
    "outputId": "2a37878c-3c90-4ce6-f6c1-dc0f4545ea3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'age', 'sibsp', 'parch', 'fare', 'embarked_C', 'embarked_Q',\n",
      "       'embarked_S', 'pclass_1', 'pclass_2', 'pclass_3', 'sex_female',\n",
      "       'sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"https://raw.github.com/mattdelhey/kaggle-titanic/master/Data/train.csv\")\n",
    "\n",
    "# impute age with median\n",
    "dataset['age'].fillna(dataset['age'].median(),inplace=True)\n",
    "\n",
    "# impute embarked with forward fill\n",
    "dataset['embarked'].fillna(method ='ffill', inplace=True)\n",
    "\n",
    "# drop name, ticket, cabin column\n",
    "dataset.drop([\"name\",\"ticket\",\"cabin\"],axis=1,inplace=True)\n",
    "\n",
    "# convert age as int\n",
    "dataset['age'] = dataset['age'].astype(int)\n",
    "\n",
    "# one hot encode Embarked column and drop it from the original df\n",
    "encoded_df = pd.get_dummies(dataset['embarked'], prefix='embarked')\n",
    "df_encoded = pd.concat([dataset, encoded_df], axis=1)\n",
    "df_encoded = df_encoded.drop('embarked', axis=1)\n",
    "\n",
    "# one hot encode Class column and drop it from the original df\n",
    "encoded_df = pd.get_dummies(df_encoded['pclass'], prefix='pclass')\n",
    "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "df_encoded = df_encoded.drop('pclass', axis=1)\n",
    "\n",
    "# one hot encode Sex column and drop it from the original df\n",
    "encoded_df = pd.get_dummies(df_encoded['sex'], prefix='sex')\n",
    "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "df_encoded = df_encoded.drop('sex', axis=1)\n",
    "\n",
    "df_encoded.head()\n",
    "print(df_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700113290676,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "-d2BKrTt49sF"
   },
   "outputs": [],
   "source": [
    "X = df_encoded.drop('survived', axis=1)  # Features\n",
    "y = df_encoded['survived']  # Target variable\n",
    "\n",
    "# print(type(X))\n",
    "# print(type(y))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "#train, test = train_test_split(df_encoded, test_size=0.2, stratify=dataset[\"survived\"], random_state=42)\n",
    "# val, test  = train_test_split(tmp, test_size=0.5, stratify=tmp[\"survived\"], random_state=42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print(type(x_train_ss))\n",
    "\n",
    "# yaha changes kar ri thi mai\n",
    "# X = df_encoded.drop('survived', axis=1)  # Features\n",
    "# y = df_encoded['survived']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9471,
     "status": "ok",
     "timestamp": 1700113300144,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "E6wxtzXq5AWd",
    "outputId": "cbaf3d38-7e72-40a4-d9e0-73611807f83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to download the TabPFN, as there is no checkpoint at  /usr/local/lib/python3.10/dist-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\n",
      "It has about 100MB, so this might take a moment.\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# is model pe lagana h deeplift\n",
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(x_test, return_winning_probability=True)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_test, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1700113300144,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "DXR2vygz5Cqv",
    "outputId": "e3785aea-e8ef-4595-cfff-c883084db000"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "x_train_t = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "x_test_t = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1700113300144,
     "user": {
      "displayName": "Shivani Mohan Agarwal",
      "userId": "18407891052881818621"
     },
     "user_tz": -330
    },
    "id": "AeH4HTex5Eb5",
    "outputId": "3a434d20-f253-4744-a5c2-6d70e8b66a5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f67f36851fe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ye implement ni kiya h abhi.. draft h bas aise hi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta, custom_attribution_func)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mmain_model_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mmain_model_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_main_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36m_hook_main_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             return [\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             ]  # type: ignore\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabPFNClassifier' object has no attribute 'register_forward_pre_hook'"
     ]
    }
   ],
   "source": [
    "# ye implement ni kiya h abhi.. draft h bas aise hi\n",
    "dl = DeepLift(classifier)\n",
    "x_train_attr = dl.attribute(x_train_t)\n",
    "y_train_attr = dl.attribute(y_train_t)\n",
    "\n",
    "x_test_attr = dl.attribute(x_test_t)\n",
    "y_test_attr = dl.attribute(y_test_t)\n",
    "\n",
    "print(x_train_attr, y_train_attr, x_test_attr, y_test_attr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
